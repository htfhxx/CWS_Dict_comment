{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import sys\n",
    "import time\n",
    "import itertools\n",
    "import models\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from config import *\n",
    "from utils_data import *\n",
    "from utils import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "train_data_path='bala_train'\n",
    "dev_data_path='bala_dev'\n",
    "test_data_path='bala_test'\n",
    "bigram_words_path='bala_train_bigram'\n",
    "config=DictConfig\n",
    "DATA_PATH='data'\n",
    "config.hidden_dim = 64\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.flags.DEFINE_string('dataset','bala',\"Dataset for evaluation\")\n",
    "tf.flags.DEFINE_string(\"model_path\", 'bala_model_path', \"The filename of model path\")\n",
    "tf.flags.DEFINE_float(\"memory\",1.0,\"Allowing GPU memory growth\")\n",
    "tf.flags.DEFINE_bool('is_train',True,\"Train or predict\")\n",
    "tf.flags.DEFINE_integer('min_bg_freq',0,'The mininum bigram_words frequency')\n",
    "tf.flags.DEFINE_string('general','bala_dict_1',\"General dictionary.\")\n",
    "tf.flags.DEFINE_string('domain',None,\"domain-specific dictionary\")\n",
    "tf.flags.DEFINE_string('model','DictHyperModel','Choose the model.')\n",
    "FLAGS = tf.flags.FLAGS\n",
    "tf.app.flags.DEFINE_string('f', '', 'kernel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oov character rate 0.002372\n"
     ]
    }
   ],
   "source": [
    "#对训练集的各个字和生成的bigram 赋予id  \n",
    "#例子：word2id={'P': 1, 'E': 0, 'U': 3, 'S': 2,'李': 5,'鹏': 6, '在': 7, '北': 8,'京'：4}\n",
    "word2id = get_word2id(train_data_path,bigram_words=bigram_words_path,min_bw_frequence=FLAGS.min_bg_freq)\n",
    "\n",
    "#最终的X_train是n(训练集的字数)个9维的列表组成的list。\n",
    "#X_train 9维数据中包含：以某个字为中心，窗口大小为5的词,包含的五个字的id，以及这个size=5窗口得到的4个bigram的id     \n",
    "#y_train是各个字对应的分词标记BIES：TAGB,TAGI,TAGE,TAGS=0,1,2,3\n",
    "X_train,y_train=get_train_data(train_data_path,word2id)\n",
    "X_valid,y_valid=get_train_data(dev_data_path,word2id)\n",
    "x_test, y_test = get_train_data(test_data_path, word2id)\n",
    "\n",
    "#得到训练集每个字所对应的特征向量：\n",
    "#代表以第i字为结尾的五字四字三字二字的词                  / 以第i字为开头的二字三字四字五字的词 \n",
    "dict_train=generate_dicttag(train_data_path,general_words_path=FLAGS.general,domain_words_path=FLAGS.domain)\n",
    "dict_valid=generate_dicttag(dev_data_path,general_words_path=FLAGS.general,domain_words_path=FLAGS.domain)\n",
    "dict_test=generate_dicttag(test_data_path,general_words_path=FLAGS.general,domain_words_path=FLAGS.domain)\n",
    "\n",
    "#词向量矩阵 len(word2id * size)\n",
    "init_embedding = get_embedding(word2id,size=config.word_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data_path: bala_train\n",
      "valid_data_path: bala_dev\n",
      "test_data_path: bala_test\n",
      "bigram_words_path: bala_train_bigram\n",
      "model_path: bala_model_path\n",
      "min_bg_freq: 0\n",
      "len(train_data): 15\n",
      "len(valid_data): 2\n",
      "len(test_data): 17\n",
      "init_embedding shape: [1686,100]\n",
      "Train started!\n"
     ]
    }
   ],
   "source": [
    "print( 'train_data_path: %s' % train_data_path )\n",
    "print( 'valid_data_path: %s' % dev_data_path)\n",
    "print( 'test_data_path: %s' % test_data_path)\n",
    "print( 'bigram_words_path: %s' % bigram_words_path)\n",
    "print( 'model_path: %s' % FLAGS.model_path)\n",
    "print( 'min_bg_freq: %d'% FLAGS.min_bg_freq)\n",
    "\n",
    "print( 'len(train_data): %d' % len(X_train))\n",
    "print( 'len(valid_data): %d' % len(X_valid))\n",
    "print( 'len(test_data): %d' % len(x_test))\n",
    "print( 'init_embedding shape: [%d,%d]' % (init_embedding.shape[0], init_embedding.shape[1]))\n",
    "print( 'Train started!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfConfig = tf.ConfigProto()\n",
    "tfConfig.gpu_options.per_process_gpu_memory_fraction = FLAGS.memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hello_World\\AppData\\Local\\conda\\conda\\envs\\py35\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:112: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "with tf.Session(config=tfConfig) as sess:\n",
    "    model=getattr(models,FLAGS.model)(vocab_size=len(word2id),word_dim=config.word_dim,hidden_dim=config.hidden_dim,\n",
    "                pad_word=word2id[PAD],init_embedding=init_embedding,num_classes=config.num_classes,clip=config.clip,\n",
    "                lr=config.lr,l2_reg_lamda=config.l2_reg_lamda,num_layers=config.num_layers,rnn_cell=config.rnn_cell,\n",
    "                bi_direction=config.bi_direction,\n",
    "                                      hidden_dim2=config.hidden_dim2,\n",
    "                                      hyper_embedding_size=config.hyper_embed_size)\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "for step,(X,dict_X,Y) in enumerate(data_iterator2(zip(X_train,dict_train),y_train,2,padding_word=word2id[PAD],shuffle=True)):\n",
    "    print(step)\n",
    "    #训练得到loss\n",
    "    #loss=model.train_step(sess,X,dict_X,Y,config.dropout_keep_prob)\n",
    "    #print( 'epoch:%d>>%2.2f%%' % (epoch,config.batch_size*step*100.0/len(X_train)),'completed in %.2f (sec) <<\\r' % (time.time()-start_time),)\n",
    "    #sys.stdout.flush()\n",
    "    #train_loss.append(loss)\n",
    "#train_loss=np.mean(train_loss,dtype=float)\n",
    "#print( 'Train Epoch %d loss %f' % (epoch, train_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X,dict_X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py35",
   "language": "python",
   "name": "py35"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
